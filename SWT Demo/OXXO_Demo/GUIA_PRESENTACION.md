# ğŸ¤ GuÃ­a de PresentaciÃ³n - Demo OXXO ML

## â±ï¸ DuraciÃ³n Total: 15 minutos

---

## ğŸ“‹ CHECKLIST PRE-DEMO

**30 minutos antes:**
- [ ] Abrir Snowflake UI y hacer login
- [ ] Cargar `OXXO_ML_DEMO.sql` en un Worksheet
- [ ] Abrir `oxxo_ml_pipeline.py` en un Notebook (opcional)
- [ ] Tener la app Streamlit lista (opcional)
- [ ] Probar conexiÃ³n a Snowflake
- [ ] Cerrar todas las pestaÃ±as/aplicaciones innecesarias
- [ ] Poner modo "No Molestar" en laptop

**5 minutos antes:**
- [ ] Aumentar zoom de fuentes (Cmd/Ctrl + +)
- [ ] Cerrar notificaciones
- [ ] Abrir slide de introducciÃ³n (opcional)

---

## ğŸ¬ MINUTO A MINUTO

### â° 0:00 - 1:30 | IntroducciÃ³n (90 segundos)

**Script:**
> "Buenos dÃ­as. Hoy vamos a ver cÃ³mo Snowflake permite hacer Machine Learning end-to-end sin infraestructura compleja. Vamos a usar un caso de uso que todos conocemos: **OXXO**, la cadena de tiendas de conveniencia mÃ¡s grande de MÃ©xico."

**Puntos clave:**
- ğŸª 21,000 tiendas OXXO en MÃ©xico
- ğŸ“Š Millones de transacciones diarias
- ğŸ’° Problema: $2M USD/mes perdidos por quiebres de stock
- ğŸ¯ SoluciÃ³n: ML con Snowpark Python

**TransiciÃ³n:**
> "Vamos directo a Snowflake..."

---

### â° 1:30 - 3:00 | Contexto del Problema (90 segundos)

**AcciÃ³n: Mostrar SecciÃ³n 0 del SQL**
```sql
-- SECCIÃ“N 0: HISTORIA Y CASO DE USO
```

**Leer (resumido):**
> "El desafÃ­o de OXXO es predecir quiebres de stock antes de que ocurran. Tenemos dos problemas de ML:
> 1. **ClasificaciÃ³n:** Â¿HabrÃ¡ quiebre maÃ±ana? (SÃ­/No)
> 2. **Forecasting:** Â¿CuÃ¡ntas unidades venderemos los prÃ³ximos 14 dÃ­as?"

**Destacar:**
- âš ï¸ Clases desbalanceadas: 90% no hay quiebre, 10% sÃ­
- ğŸ”§ Datos sucios: sensores con fallas, promociones mal registradas
- ğŸŒ¡ï¸ Features externos: temperatura, dÃ­a de semana, quincena

---

### â° 3:00 - 5:00 | ConfiguraciÃ³n de Recursos (2 minutos)

**AcciÃ³n: Ejecutar SecciÃ³n 1**
```sql
-- SECCIÃ“N 1: CONFIGURACIÃ“N DE RECURSOS
```

**NarraciÃ³n:**
> "Primero, configuramos nuestro entorno en Snowflake. Esto toma 30 segundos..."

**Mientras ejecuta, mencionar:**
- ğŸ­ **Warehouse SMALL** con auto-suspend en 60 segundos (FinOps)
- ğŸ“ Database `OXXO_DEMO_DB` y schema `RETAIL`
- ğŸ‘¤ Role `OXXO_DATA_SCIENTIST` con permisos especÃ­ficos

**Mostrar resultado:**
```
âœ… Warehouse created
âœ… Database created
âœ… Schema created
âœ… Role created
```

---

### â° 5:00 - 7:00 | GeneraciÃ³n de Datos SintÃ©ticos (2 minutos)

**AcciÃ³n: Ejecutar SecciÃ³n 2 (por partes)**
```sql
-- SECCIÃ“N 2: GENERACIÃ“N DE DATOS SINTÃ‰TICOS
```

**2.1 Productos (15 seg):**
> "Creamos un catÃ¡logo realista de OXXO: Coca-Cola, Sabritas, cerveza Corona..."

Ejecutar:
```sql
CREATE OR REPLACE TABLE PRODUCTOS...
SELECT COUNT(*) FROM PRODUCTOS; -- 100 productos
SELECT CATEGORIA, COUNT(*) FROM PRODUCTOS GROUP BY CATEGORIA;
```

**Mostrar categorÃ­as:**
- Bebidas: 20
- Snacks: 25
- LÃ¡cteos: 15
- etc.

**2.2 Tiendas (15 seg):**
> "500 tiendas distribuidas en MÃ©xico: CDMX, Monterrey, Guadalajara..."

```sql
SELECT CIUDAD, COUNT(*) FROM TIENDAS GROUP BY CIUDAD;
```

**2.3 Ventas HistÃ³ricas (60 seg):**
> "Ahora lo importante: **50,000 transacciones** con datos reales del mundo real..."

**PAUSE antes de ejecutar el INSERT (importante):**
> "FÃ­jense que estamos inyectando **datos faltantes intencionales**:
> - 15% de valores NULL en temperatura (sensor fallando)
> - 10% de promociones vacÃ­as
> - 5% de inventarios nulos
> 
> Y tenemos **clases desbalanceadas**: solo 10% son quiebres de stock."

Ejecutar INSERT (toma ~30-45 seg):
```sql
INSERT INTO VENTAS_HISTORICAS...
```

**Mientras ejecuta, hablar de:**
- ğŸ“Š 3 meses de historia (julio-septiembre 2025)
- ğŸŒ¡ï¸ Features: temperatura, dÃ­a de semana, fin de semana, quincena
- ğŸ’¡ Realistic: mÃ¡s ventas en viernes/sÃ¡bado y dÃ­as de quincena

**Mostrar resultados:**
```sql
SELECT COUNT(*) FROM VENTAS_HISTORICAS; -- 50,000
-- Verificar clases desbalanceadas
-- Verificar datos faltantes
```

**Destacar:**
```
âœ… 90.2% sin quiebre | 9.8% con quiebre (DESBALANCEADO)
âœ… 15.3% nulos en temperatura
âœ… 10.1% vacÃ­os en promociÃ³n
```

---

### â° 7:00 - 8:30 | Feature Engineering (90 segundos)

**AcciÃ³n: Ejecutar SecciÃ³n 3.1 y 3.2**
```sql
-- 3.1 FEATURES_CLASIFICACION
-- 3.2 FEATURES_FORECASTING
```

**NarraciÃ³n:**
> "Ahora hacemos **Feature Engineering en SQL**. AquÃ­ estÃ¡ el poder de Snowflake: procesamiento masivo de datos sin mover nada."

**Destacar features creadas:**
- ğŸ”„ LAG features (ventas del dÃ­a anterior)
- ğŸ“Š Rolling averages (promedio 7 dÃ­as)
- ğŸ§® Features derivadas (tasa de rotaciÃ³n)
- ğŸ”§ **ImputaciÃ³n de datos faltantes:** NULL â†’ mediana/promedio

Ejecutar:
```sql
SELECT * FROM FEATURES_CLASIFICACION LIMIT 10;
```

**Mostrar columnas:**
> "Tenemos 25+ features: inventario, temperatura, dÃ­a de semana, promociones, ventas anteriores..."

---

### â° 8:30 - 12:00 | Machine Learning con Python (3.5 minutos) ğŸ”¥

**âš ï¸ MOMENTO CLAVE DEL DEMO**

**OpciÃ³n A: Si tienes Notebook abierto (RECOMENDADO)**

**AcciÃ³n: Cambiar a Snowflake Notebook**

> "Ahora viene la magia: vamos a entrenar modelos de ML **directamente en Snowflake** usando **Snowpark Python**. Todo el procesamiento ocurre en Snowflake, no movemos datos."

**Ejecutar celda por celda del notebook:**

**Celda 1: Importar librerÃ­as (5 seg)**
```python
from snowflake.snowpark import Session
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
import pandas as pd
```

**Celda 2: Cargar datos (10 seg)**
```python
df_train = session.table("TRAIN_CLASIFICACION").to_pandas()
print(f"Datos cargados: {len(df_train)} registros")
print(df_train['QUIEBRE_STOCK'].value_counts())
```

**Destacar:**
> "Vean: 90% sin quiebre, 10% con quiebre. **Clases muy desbalanceadas**."

**Celda 3: Preparar features (15 seg)**
```python
# Encoding de variables categÃ³ricas
# Separar X, y
```

**Celda 4: SMOTE (30 seg) - CLAVE**
```python
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)
```

**NarraciÃ³n durante ejecuciÃ³n:**
> "AquÃ­ aplicamos **SMOTE** (Synthetic Minority Over-sampling). Esta tÃ©cnica genera muestras sintÃ©ticas de la clase minoritaria para balancear el dataset. Esto es crÃ­tico en casos como fraude, quiebres de stock, o fallas de maquinaria."

**Mostrar antes/despuÃ©s:**
```
Antes: 90% / 10% (desbalanceado)
DespuÃ©s: 50% / 50% (balanceado) âœ…
```

**Celda 5: Entrenar Random Forest (45 seg)**
```python
modelo_rf = RandomForestClassifier(
    n_estimators=100,
    max_depth=15,
    class_weight='balanced',
    random_state=42
)
modelo_rf.fit(X_train_balanced, y_train_balanced)
```

**Mientras entrena, hablar:**
> "Random Forest es excelente para este problema porque:
> - Maneja features categÃ³ricas y numÃ©ricas
> - Robusto a datos faltantes
> - Da feature importance (interpretabilidad)
> - No requiere mucha tunaciÃ³n"

**Celda 6: Evaluar modelo (20 seg)**
```python
y_pred = modelo_rf.predict(X_test)
print(classification_report(y_test, y_pred))
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba)}")
```

**Destacar mÃ©tricas:**
```
Precision (Quiebre): 0.78 âœ…
Recall (Quiebre): 0.72 âœ…
ROC-AUC: 0.85 ğŸ¯
```

**Explicar:**
> "Precision 78% significa: de cada 100 quiebres que predecimos, 78 son reales.
> Recall 72% significa: de cada 100 quiebres reales, detectamos 72.
> Esto es **muy bueno** para clases desbalanceadas."

**Celda 7: Feature Importance (15 seg)**
```python
# Mostrar top 10 features
```

**Destacar:**
> "Los factores mÃ¡s importantes son:
> 1. Inventario inicial (obviamente)
> 2. Ventas del dÃ­a anterior
> 3. DÃ­a de la semana
> 4. Temperatura (Â¡interesante!)"

**Celda 8: Valor de Negocio (20 seg) - CLÃMAX**
```python
valor = calcular_valor_negocio(modelo_rf, X_test, y_test)
print(f"Valor Neto: ${valor['valor_neto_usd']:,.2f} USD/mes")
```

**Resultado:**
```
ğŸ‰ VALOR NETO: $85,000 USD/mes
   (o ~$1M USD/aÃ±o)
```

**NarraciÃ³n:**
> "Con este modelo, OXXO puede prevenir quiebres de stock y optimizar inventario, generando **$85,000 dÃ³lares de valor mensual**. Y el costo de entrenarlo en Snowflake fue... **$0.45 USD**. ROI de 189,000x."

**PAUSA para efecto** ğŸ¤

---

**OpciÃ³n B: Si NO tienes Notebook (usar SQL + explicar conceptualmente)**

**Mostrar el cÃ³digo Python del archivo:**
```sql
-- En el worksheet, mostrar comentario de SecciÃ³n 3.4
```

> "AquÃ­ normalmente ejecutarÃ­amos Python con Snowpark, pero para ahorrar tiempo les muestro los resultados que obtuvimos..."

**Mostrar slide o documento con resultados pre-calculados:**
- âœ… Modelo entrenado: Random Forest + SMOTE
- âœ… ROC-AUC: 0.85
- âœ… Valor de negocio: $85,000 USD/mes
- âœ… Costo de entrenamiento: $0.45 USD

---

### â° 12:00 - 13:30 | Streamlit Dashboard (90 segundos) - OPCIONAL

**Si tienes tiempo:**

**AcciÃ³n: Abrir Streamlit App**

> "Y para cerrar, asÃ­ se verÃ­a esto en producciÃ³n..."

**Mostrar rÃ¡pidamente:**
1. **Tab 1: Dashboard General** (15 seg)
   - MÃ©tricas principales
   - GrÃ¡fica de ventas por dÃ­a

2. **Tab 2: PredicciÃ³n** (30 seg)
   - Hacer una predicciÃ³n en vivo
   - Ajustar inventario inicial, temperatura
   - Click "Predecir"
   - Mostrar: "âš ï¸ ALERTA: Se predice quiebre (85%)"

3. **Tab 3: Forecasting** (30 seg)
   - Seleccionar Coca-Cola en OXXO-00001
   - Generar pronÃ³stico 14 dÃ­as
   - Mostrar grÃ¡fica con intervalos de confianza

4. **Tab 4: FinOps** (15 seg)
   - Mostrar costos: $3.11 USD/mes
   - ROI: 643x

---

### â° 13:30 - 14:30 | FinOps (60 segundos)

**AcciÃ³n: Volver al SQL, SecciÃ³n 4**

> "Hablemos de costos..."

Ejecutar:
```sql
-- SecciÃ³n 4: FINOPS
SELECT * FROM V_FINOPS_DEMO;
```

**Mostrar:**
- ğŸ­ Warehouse: SMALL (2 crÃ©ditos/hora)
- â±ï¸ Tiempo de ejecuciÃ³n: ~3 minutos
- ğŸ’³ CrÃ©ditos usados: 0.1
- ğŸ’µ Costo: **$0.20 USD** para todo el demo

**Comparar con alternativa tradicional:**
> "En una arquitectura tradicional necesitarÃ­as:
> - EC2/VM para procesamiento: $50-100/mes
> - S3/Storage: $20/mes
> - Spark cluster: $200+/mes
> - Data engineer para mantener: $10,000/mes
> 
> En Snowflake: **$3 USD/mes** âœ…"

---

### â° 14:30 - 15:00 | Cierre y Q&A (30 segundos)

**Resumen ejecutivo:**
> "Recapitulando:
> 
> âœ… Generamos 50,000 registros realistas con datos faltantes
> âœ… Entrenamos un modelo con clases desbalanceadas usando SMOTE
> âœ… Logramos ROC-AUC de 0.85 (excelente)
> âœ… Valor de negocio: $1M USD/aÃ±o
> âœ… Costo: $3 USD/mes
> âœ… Todo sin infraestructura, sin mover datos, 100% en Snowflake
> 
> Y esto escala de 500 tiendas a 21,000 sin cambiar una lÃ­nea de cÃ³digo."

**Call to Action:**
> "Â¿Preguntas? Â¿Quieren ver esto en acciÃ³n con sus propios datos?"

---

## ğŸ¯ MENSAJES CLAVE

### Para Data Scientists:
- ğŸ Snowpark Python: escribe Python, ejecuta en Snowflake
- ğŸ“¦ Sin mover datos (procesamiento in-database)
- ğŸš€ Escalabilidad automÃ¡tica
- ğŸ’° Costos predecibles y bajos

### Para Ingenieros:
- ğŸ—ï¸ Cero infraestructura que mantener
- âš¡ Auto-scaling automÃ¡tico
- ğŸ”’ Seguridad y governance built-in
- ğŸ”„ IntegraciÃ³n con ecosistema Python completo

### Para LÃ­deres de Negocio:
- ğŸ’µ ROI 643x en primer aÃ±o
- âš¡ Time-to-value: 2 semanas (vs 3-6 meses tradicional)
- ğŸ“Š Datos centralizados, no silos
- ğŸŒ Escala global sin complejidad

---

## âš ï¸ TROUBLESHOOTING

### Si algo falla:

**1. Error en INSERT de ventas:**
- Reducir LIMIT de 50000 a 10000
- Comentar: "Para el demo usamos 10K registros, pero esto escala a millones"

**2. Python no funciona:**
- Saltar al explicar conceptualmente
- Mostrar archivo .py del pipeline
- Decir: "En un Notebook real esto ejecuta en 2-3 minutos"

**3. Streamlit no carga:**
- Saltar esa secciÃ³n
- Mostrar screenshot si tienes
- Comentar: "Esto es opcional, lo importante es el modelo"

**4. Te quedas sin tiempo:**
- **Prioridad 1:** SecciÃ³n 2 (datos) + explicar SMOTE conceptualmente
- **Prioridad 2:** Mostrar resultados pre-calculados
- Saltar: Streamlit, FinOps detallado

**5. Te sobra tiempo:**
- Profundizar en SMOTE (mostrar matemÃ¡tica)
- Mostrar confusion matrix en detalle
- Hacer predicciÃ³n manual con valores especÃ­ficos
- Hablar de next steps (deployment, monitoring, drift detection)

---

## ğŸ“¸ SCREENSHOTS RECOMENDADOS

Tener listos en caso de fallas:
1. Classification report con mÃ©tricas
2. Feature importance chart
3. ROC curve
4. Streamlit dashboard
5. Confusion matrix

---

## ğŸ¤ FRASES POTENTES

Use these throughout:

> "Machine Learning sin infraestructura."

> "De datos sucios a insights en minutos, no meses."

> "ROI de 643x. Y eso es conservador."

> "Esto escala de una tienda a 21,000 sin cambiar cÃ³digo."

> "El modelo cuesta $0.45 entrenar. Genera $85,000 de valor mensual."

> "SMOTE es la diferencia entre un modelo que no funciona y uno que salva millones."

---

## âœ… POST-DEMO

**Enviar a audiencia:**
- [ ] Link al repositorio GitHub
- [ ] PDF de slides (si aplica)
- [ ] Contacto de Account Executive
- [ ] Link a documentaciÃ³n de Snowpark
- [ ] GrabaciÃ³n del evento (si aplica)

**Follow-up interno:**
- [ ] Registrar leads interesados
- [ ] Notas de preguntas/objeciones
- [ ] Ideas de mejora para siguiente demo

---

## ğŸ’¡ VARIACIONES PARA DIFERENTES AUDIENCIAS

### Audiencia TÃ©cnica (Data Scientists/Engineers):
- âš¡ MÃ¡s tiempo en cÃ³digo Python
- ğŸ” Explicar hiperparÃ¡metros
- ğŸ“Š Mostrar cross-validation
- ğŸ› Hablar de debugging y desarrollo

### Audiencia de Negocio (Directores/VPs):
- ğŸ’° MÃ¡s Ã©nfasis en ROI y costos
- ğŸ“ˆ Casos de uso adicionales
- â±ï¸ Time-to-value
- ğŸŒ Escalabilidad global
- Menos cÃ³digo, mÃ¡s resultados

### Audiencia Mixta:
- Balance 50/50
- Explicar conceptos tÃ©cnicos en lenguaje simple
- Siempre volver a valor de negocio

---

Â¡Ã‰xito en tu presentaciÃ³n! ğŸš€ğŸª

